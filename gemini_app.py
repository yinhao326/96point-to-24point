import streamlit as st
import pandas as pd
import numpy as np
import io
import re
import math
import datetime
# å¼•å…¥æ–°ç‰ˆ SDK
from google import genai

# ================= 0. é…ç½®ä¸åˆå§‹åŒ– =================

st.set_page_config(page_title="AI èƒ½æºåˆ†æå° (Cloudç‰ˆ)", layout="wide")

# âŒ åˆ é™¤æ‰€æœ‰ os.environ è®¾ç½®ä»£ç†çš„ä»£ç 
# Streamlit Cloud åœ¨æµ·å¤–ï¼Œç›´è¿ Googleï¼Œä¸éœ€è¦ä»£ç†ï¼

# æ£€æŸ¥ API Key
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
else:
    st.error("âŒ æœªæ£€æµ‹åˆ° API Keyã€‚è¯·åœ¨ Streamlit Cloud æ§åˆ¶å°çš„ Secrets ä¸­é…ç½® GEMINI_API_KEY")
    st.stop()

# åˆå§‹åŒ–å®¢æˆ·ç«¯
try:
    # çº¯å‡€åˆå§‹åŒ–ï¼Œä¸å¸¦ä»»ä½• proxy å‚æ•°
    client = genai.Client(
        api_key=api_key,
        http_options={"timeout": 60000} # åªä¿ç•™è¶…æ—¶è®¾ç½®
    )
except Exception as e:
    st.error(f"æ— æ³•åˆå§‹åŒ–å®¢æˆ·ç«¯: {e}")
    st.stop()

# ================= 1. æ ¸å¿ƒå·¥å…·å‡½æ•° =================

def clean_energy_time(series):
    """
    ã€èƒ½æºè¡Œä¸šæ—¶é—´æ¸…æ´—å™¨ã€‘è§£å†³ '24:00' é—®é¢˜
    """
    def parse_single_val(val):
        s_val = str(val).strip()
        if "24:00" in s_val:
            temp_s = s_val.replace("24:00", "00:00")
            try:
                dt = pd.to_datetime(temp_s)
                if len(s_val) > 8: 
                    return dt + pd.Timedelta(days=1)
                return dt
            except:
                return pd.NaT
        else:
            try:
                return pd.to_datetime(val)
            except:
                return pd.NaT

    try:
        return pd.to_datetime(series)
    except:
        return series.apply(parse_single_val)

# ================= 2. å…¨å±€çŠ¶æ€ç®¡ç† =================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "current_df" not in st.session_state:
    st.session_state.current_df = None
if "file_hash" not in st.session_state:
    st.session_state.file_hash = None

# ================= 3. ä¾§è¾¹æ  =================
with st.sidebar:
    st.title("ğŸ§  è®¾ç½®")
    
    # ç¡¬ç¼–ç æ¨¡å‹åˆ—è¡¨
    model_options = [
        "gemini-2.5-flash",       # æˆªå›¾ä¸­çš„æ–°æ¨¡å‹ï¼ˆæ¨èé¦–é€‰ï¼Œé€Ÿåº¦å¿«ï¼‰
        "gemini-2.5-pro",         # æˆªå›¾ä¸­çš„å¼ºåŠ›æ¨¡å‹
        "gemini-1.5-flash",   # 1.5 çš„ç¨³å®šç‰ˆï¼ˆå¦‚æœ 2.5 æŠ¥é”™ï¼Œå°±åˆ‡å›è¿™ä¸ªï¼‰
        "gemini-1.5-pro",     # 1.5 çš„å¼ºåŠ›ç¨³å®šç‰ˆ
    ]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹å¼•æ“ï¼š", model_options, index=0)
    
    st.success("â˜ï¸ äº‘ç«¯ç¯å¢ƒï¼šå·²è‡ªåŠ¨ç›´è¿ Google")

    st.divider()
    st.header("ğŸ“‚ æ–‡ä»¶ä¸Šä¼ ")
    uploaded_file = st.file_uploader("ä¸Šä¼  Excel/CSV", type=["xlsx", "xls", "csv"])
    
    if uploaded_file:
        current_hash = hash(uploaded_file.getvalue())
        if st.session_state.file_hash != current_hash:
            try:
                if uploaded_file.name.endswith('.csv'):
                    st.session_state.current_df = pd.read_csv(uploaded_file)
                else:
                    st.session_state.current_df = pd.read_excel(uploaded_file)
                
                st.session_state.file_hash = current_hash
                st.session_state.chat_history = [{
                    "role": "assistant", 
                    "content": f"âœ… **{uploaded_file.name}** åŠ è½½æˆåŠŸï¼(å¼•æ“: {selected_model})\nè¯·å‘Šè¯‰æˆ‘æ€ä¹ˆå¤„ç†æ•°æ®ã€‚"
                }]
                st.rerun()
            except Exception as e:
                st.error(f"âŒ è¯»å–å¤±è´¥: {e}")

    if st.button("ğŸ”¥ é‡ç½®å·¥ä½œåŒº", type="primary", use_container_width=True):
        st.session_state.file_hash = None
        st.session_state.current_df = None
        st.session_state.chat_history = []
        st.rerun()

    if st.session_state.current_df is not None:
        st.divider()
        out = io.BytesIO()
        with pd.ExcelWriter(out, engine='openpyxl') as writer:
            st.session_state.current_df.to_excel(writer, index=False) # è¿™é‡Œçš„ index=False è§†æƒ…å†µè€Œå®š
        st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ", out.getvalue(), "Result.xlsx", use_container_width=True)

# ================= 4. ä¸»ç•Œé¢ =================
st.title("âš¡ AI èƒ½æºæ•°æ®åˆ†æå° (Cloud V34)")

if st.session_state.current_df is None:
    st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶")
    st.stop()

# æ•°æ®é¢„è§ˆ
with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ (Top 5)", expanded=True):
    st.dataframe(st.session_state.current_df.head(5), use_container_width=True)

# èŠå¤©è®°å½•
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

# ================= 5. Gemini æ ¸å¿ƒå¼•æ“ =================

if user_prompt := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤..."):
    st.session_state.chat_history.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"): st.markdown(user_prompt)
    
    with st.chat_message("assistant"):
        status = st.status("âœ¨ AI æ­£åœ¨æ€è€ƒ...", expanded=True)
        
        try:
            # å‡†å¤‡ Prompt
            df_sample = st.session_state.current_df.head(5).to_markdown()
            df_dtypes = str(st.session_state.current_df.dtypes)
            
            prompt = f"""
            You are an expert Python Data Analyst.
            
            ã€Data Contextã€‘
            {df_sample}
            Types: {df_dtypes}
            
            ã€User Requestã€‘
            {user_prompt}
            
            ã€Requirementsã€‘
            1. Return ONLY valid Python code inside ```python blocks.
            2. Define a function `def process_step(df):` that returns the modified dataframe.
            3. Use `clean_energy_time(series)` for date parsing if needed.
            4. Assume necessary libraries (pd, np, re) are imported.
            """
            
            status.write("æ­£åœ¨è¯·æ±‚ Google API (Cloud Direct)...")
            
            # è°ƒç”¨ç”Ÿæˆ API
            response = client.models.generate_content(
                model=selected_model,
                contents=prompt
            )
            
            # æå–ä»£ç 
            raw_code = response.text
            # ç®€å•çš„ä»£ç æå–é€»è¾‘
            if "```python" in raw_code:
                cleaned_code = raw_code.split("```python")[1].split("```")[0].strip()
            elif "```" in raw_code:
                cleaned_code = raw_code.split("```")[1].split("```")[0].strip()
            else:
                cleaned_code = raw_code.strip()
            
            status.write("æ­£åœ¨æ‰§è¡Œç”Ÿæˆçš„ä»£ç ...")
            
            # æ‰§è¡Œç¯å¢ƒ
            execution_globals = {
                "pd": pd, "np": np, "re": re, "math": math, 
                "datetime": datetime, "clean_energy_time": clean_energy_time 
            }
            local_scope = {}
            
            exec(cleaned_code, execution_globals, local_scope)
            
            if 'process_step' in local_scope:
                new_df = local_scope['process_step'](st.session_state.current_df.copy())
                
                st.session_state.current_df = new_df
                status.update(label="âœ… æ‰§è¡ŒæˆåŠŸ", state="complete", expanded=False)
                
                result_msg = f"âœ… å¤„ç†å®Œæˆã€‚ç»“æœå½¢çŠ¶: {new_df.shape}"
                st.session_state.chat_history.append({"role": "assistant", "content": result_msg})
                st.rerun()
            else:
                status.update(label="âŒ å‡½æ•°ä¸¢å¤±", state="error")
                st.error("AI æœªç”Ÿæˆ process_step å‡½æ•°")
                st.code(cleaned_code)

        except Exception as e:
            status.update(label="âŒ å‘ç”Ÿé”™è¯¯", state="error")
            st.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")



